{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\calli\\\\Anaconda3\\\\envs\\\\opencv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\") # have to use this for tkinter to  work below\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib tk\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import skimage.io as io\n",
    "\n",
    "import os\n",
    "\n",
    "import imageio\n",
    "# print environment\n",
    "os.path.dirname(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust gamma\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "        for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    " \n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vidPath = \"D:/BeeTwoFlowerExperiment/2018_02_27__14_04_52_556/2018_02_27__14_04_55_680_cam1-0000.avi\"\n",
    "vidPath = r\"D:\\Dropbox\\AcademiaDropbox\\dataAnalysisForOthers\\SujayFish\\BML 17-23.avi\"\n",
    "os.path.isfile(vidPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488 708 480 10.0\n"
     ]
    }
   ],
   "source": [
    "# get vid info\n",
    "cap = cv2.VideoCapture(vidPath)\n",
    "\n",
    "\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "print(length, width, height, fps)\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imgs(vidPath, start, stop):\n",
    "    cap = cv2.VideoCapture(vidPath)\n",
    "    imgs = []\n",
    "    for ff in range(length):\n",
    "        \n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if np.mod(ff, 50) == 0:\n",
    "            print(ff)\n",
    "        \n",
    "    \n",
    "        # convert to grey\n",
    "        img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #adjust gamma\n",
    "        img = adjust_gamma(img, gamma=3.0)\n",
    "        \n",
    "        # convert dtype\n",
    "        img = img.astype(\"int16\")\n",
    "        imgs.append(img)\n",
    "        \n",
    "        if ff > stop:\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n"
     ]
    }
   ],
   "source": [
    "imgs = load_imgs(vidPath, 0, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1401dc4a3c8>]"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize images\n",
    "\n",
    "plt.plot(np.percentile(np.array(imgs), axis = (2,1), q = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14025274978>"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.matshow(imgs[0] * (255 / np.percentile(np.array(imgs[0]), axis = (0,1), q = 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3394495412844036"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255 / np.percentile(np.array(imgs[0]), axis = (0,1), q = 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105.0"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(np.array(imgs[0]), axis = (0,1), q = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play video\n",
    "for ii in range(len(imgs)):\n",
    "    frame = ((imgs[ii] < 120 )* 255).astype(\"uint8\")\n",
    "    \n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('Frame', frame) \n",
    "   \n",
    "    # Press Q on keyboard to  exit \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'): \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkgImg = np.median(np.array(imgs), axis = (0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play video\n",
    "for ii in range(len(imgs)):\n",
    "    frame = ((imgs[ii] -  bkgImg < -8 )* 255).astype(\"uint8\")\n",
    "    \n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('Frame', frame) \n",
    "   \n",
    "\n",
    "    # Press Q on keyboard to  exit \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'): \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play video\n",
    "for ii in range(len(imgs)):\n",
    "    ti = imgs[ii] -  bkgImg\n",
    "    frame = ((ti + abs(np.min(ti))) / np.max((ti + abs(np.min(ti))))* 255).astype(\"uint8\")\n",
    "    \n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('Frame', frame) \n",
    "   \n",
    "\n",
    "    # Press Q on keyboard to  exit \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'): \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(488, 480, 708)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(imgs).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 708)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101., 109., 114., ..., 125., 126., 126.],\n",
       "       [ 99., 108., 112., ..., 125., 126., 126.],\n",
       "       [ 99., 108., 114., ..., 126., 124., 125.],\n",
       "       ...,\n",
       "       [112., 120., 125., ..., 115., 115., 115.],\n",
       "       [112., 120., 124., ..., 114., 114., 113.],\n",
       "       [112., 120., 124., ...,  60.,  63.,  60.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(np.array(imgs[290:310]), axis = 0, q =50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[101., 109., 114., ..., 125., 126., 126.],\n",
       "       [ 99., 108., 112., ..., 125., 126., 126.],\n",
       "       [ 99., 108., 114., ..., 126., 124., 125.],\n",
       "       ...,\n",
       "       [112., 120., 125., ..., 115., 115., 115.],\n",
       "       [112., 120., 124., ..., 114., 114., 113.],\n",
       "       [112., 120., 124., ...,  60.,  63.,  60.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.median(np.array(imgs[290:310]), axis = (0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(imgs[0])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(np.median(np.array(imgs[290:310]), axis = (0)))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(np.percentile(np.array(imgs[280:320]), axis = (0), q =99))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(np.array(imgs[300]))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "subtractedImgs = []\n",
    "fnum = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "fnum += 0\n",
    "    \n",
    "medStart = np.max((0,fnum - 30))\n",
    "medEnd = np.min((length, fnum + 30))\n",
    "\n",
    "\n",
    "\n",
    "bkgSubtractImg = np.percentile(np.array(imgs[medStart:medEnd]), axis = (0), q = 99.9) - imgs[fnum]\n",
    "subtractedImgs.append(bkgSubtractImg)\n",
    "print(fnum)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "img = ax[0].imshow(bkgSubtractImg)\n",
    "plt.colorbar(img, ax=ax[0])\n",
    "img2 = ax[1].imshow(imgs[fnum])\n",
    "plt.colorbar(img2, ax=ax[1])\n",
    "fnum += 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "300\n",
      "320\n",
      "340\n",
      "360\n",
      "380\n",
      "400\n",
      "420\n",
      "440\n",
      "460\n",
      "480\n"
     ]
    }
   ],
   "source": [
    "halfWinLen = 40\n",
    "subtractedImgs = []\n",
    "\n",
    "\n",
    "for fnum in range(len(imgs)):\n",
    "    \n",
    "    medStart = np.max((0,fnum - halfWinLen))\n",
    "    medEnd = np.min((length, fnum + halfWinLen))\n",
    "\n",
    "\n",
    "\n",
    "    bkgSubtractImg = np.percentile(np.array(imgs[medStart:medEnd]), axis = (0), q = 99) - imgs[fnum]\n",
    "    subtractedImgs.append(bkgSubtractImg)\n",
    "    \n",
    "    if np.mod(fnum, 20) == 0:\n",
    "        print(fnum)\n",
    "\n",
    "#fig, ax = plt.subplots(2, 1)\n",
    "# img = ax[0].imshow(bkgSubtractImg)\n",
    "# plt.colorbar(img, ax=ax[0])\n",
    "# img2 = ax[1].imshow(imgs[fnum])\n",
    "# plt.colorbar(img2, ax=ax[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale changeImages between 0 and 255\n",
    "changeBlur = []\n",
    "for ii in range(len(subtractedImgs)):\n",
    "    blurredImg = cv2.GaussianBlur(subtractedImgs[ii], (5,5) ,0)\n",
    "    \n",
    "    tmpImg = ((255*(blurredImg + abs(np.min(blurredImg))) / \n",
    "            np.max(blurredImg+ abs(np.min(blurredImg)))).astype(\"uint8\"))\n",
    "    \n",
    "    # invert img\n",
    "    imagem = cv2.bitwise_not(tmpImg)\n",
    "    \n",
    "    changeBlur.append(imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play video\n",
    "for ii in range(len(changeBlur)):\n",
    "    frame = (changeBlur[ii]).astype(\"uint8\")\n",
    "    \n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('Frame', frame) \n",
    "   \n",
    "    # Press Q on keyboard to  exit \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'): \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file\n",
    "\n",
    "writeFile = r\"D:\\Dropbox\\AcademiaDropbox\\dataAnalysisForOthers\\SujayFish\\processedVid.avi\"\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "\n",
    "out = cv2.VideoWriter(writeFile,fourcc, 25.0, (width,height), 0)\n",
    "for ii in range(len(changeBlur)):\n",
    "    frame = (changeBlur[ii]).astype(\"uint8\")\n",
    "    # Display the resulting frame \n",
    "    #cv2.imshow('Frame', frame) \n",
    "   \n",
    "    # Press Q on keyboard to  exit \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'): \n",
    "        break\n",
    "    out.write(frame)\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold\n",
    "# scale changeImages between 0 and 255\n",
    "threshImg = []\n",
    "for ii in range(len(changeBlur)):\n",
    "    tmpImg = ((changeBlur[ii] > 170* 1.0)*255).astype(\"uint8\")\n",
    "    threshImg.append(tmpImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play video\n",
    "for ii in range(len(threshImg)):\n",
    "    frame = (threshImg[ii]).astype(\"uint8\")\n",
    "    \n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('Frame', frame) \n",
    "   \n",
    "    # Press Q on keyboard to  exit \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'): \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove blobs\n",
    "\n",
    "ii = 200\n",
    "img, cnts, _ = cv2.findContours(threshImg[ii], cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     mask = np.ones(threshImg[ii], dtype=\"uint8\") * 0 # create a blank black mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = np.array([cv2.contourArea(c, False) for c in cnts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = (threshImg[ii]).astype(\"uint8\")\n",
    "    \n",
    "# Display the resulting frame \n",
    "cv2.imshow('Frame', frame) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.000e+00, 2.500e+00, 3.100e+01, 1.600e+01, 1.750e+01, 1.050e+01,\n",
       "       2.300e+01, 5.600e+01, 5.300e+01, 4.800e+01, 1.000e+02, 1.990e+02,\n",
       "       4.450e+01, 6.395e+02, 4.000e+00, 2.000e+00, 4.750e+01, 8.000e+00,\n",
       "       9.000e+00, 3.500e+00, 3.500e+00, 2.750e+01, 3.500e+01, 2.000e+00,\n",
       "       1.950e+01, 4.000e+01, 2.050e+01, 2.650e+01, 2.550e+01, 7.750e+01,\n",
       "       1.500e+00, 7.000e+00, 7.600e+01, 3.600e+01, 1.700e+01, 1.000e+01,\n",
       "       0.000e+00, 2.050e+01, 1.280e+02, 8.500e+00, 2.500e+00, 4.750e+01,\n",
       "       1.955e+02, 1.400e+01, 2.595e+02, 1.840e+02, 4.300e+01, 2.558e+03,\n",
       "       0.000e+00, 1.160e+02, 9.800e+01, 6.000e+01])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.median(np.array(changeBlur), axis = (1,2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# over time, the background gets lighter\n",
    "# 0 is black, 255 is white\n",
    "plt.clf()\n",
    "plt.plot(np.median(np.array(imgs), axis = (1,2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n"
     ]
    }
   ],
   "source": [
    "# calculate changing background\n",
    "window_length = 20\n",
    "vidLen = length\n",
    "\n",
    "\n",
    "bkgList = []\n",
    "\n",
    "for ii in np.arange(1, length):\n",
    "    \n",
    "    if np.mod(ii, 50) == 0:\n",
    "        print(ii)\n",
    "    start = np.max((0, ii-(window_length//2)))\n",
    "    endd = np.min((vidLen, ii+(window_length//2) ))\n",
    "        \n",
    "    tmpBkg = np.median(np.array(imgs)[start:endd, :, :], axis = (0))\n",
    "    bkgList.append(tmpBkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# play video\n",
    "for ii in np.arange(1,len(imgs)):\n",
    "    frame = ((imgs[ii] -  bkgList[ii-1] < 5)* 255).astype(\"uint8\")\n",
    "    \n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('Frame', frame) \n",
    "   \n",
    "\n",
    "    # Press Q on keyboard to  exit \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'): \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.median(np.array(bkgList), axis = (1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play video\n",
    "for ii in range(len(bkgList)):\n",
    "    frame = (bkgList[ii]).astype(\"uint8\")\n",
    "    \n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('Frame', frame) \n",
    "   \n",
    "    # Press Q on keyboard to  exit \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'): \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract background\n",
    "imArray = np.array(imgs)\n",
    "\n",
    "# threshold only stuff that gets darker ( that is, change is > 0)\"\"\n",
    "changeImgs = np.array([(bkgList[ii] - imArray[ii, :, :])  for ii in range(len(bkgList))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract background\n",
    "imArray = np.array(imgs)\n",
    "\n",
    "# threshold only stuff that gets darker ( that is, change is > 0)\"\"\n",
    "changeImgs = np.array([(bkgImg - imArray[ii, :, :]) for ii in range(len(bkgList))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(changeImgs[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(changeImgs[200].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(changeImgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 0 \n",
    "frame = (changeImgs[ii]).astype(\"uint8\")\n",
    "cv2.imshow('Frame', frame) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract background\n",
    "imArray = np.array(imgs)\n",
    "\n",
    "# threshold only stuff that gets darker ( that is, change is > 0)\"\"\n",
    "changeImgs = np.array([(bkgImg - imArray[ii, :, :]) for ii in range(len(bkgList))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale changeImages between 0 and 255\n",
    "changeBlur = []\n",
    "for ii in range(len(changeImgs)):\n",
    "    blurredImg = cv2.GaussianBlur(changeImgs[ii], (15,15) ,0)\n",
    "    \n",
    "    tmpImg = ((255*(blurredImg + abs(np.min(blurredImg))) / \n",
    "            np.max(blurredImg+ abs(np.min(blurredImg)))).astype(\"uint8\"))\n",
    "    \n",
    "    changeBlur.append(tmpImg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play video\n",
    "for ii in range(len(changeBlur)):\n",
    "    frame = (changeBlur[ii]).astype(\"uint8\")\n",
    "    \n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('Frame', frame) \n",
    "   \n",
    "    # Press Q on keyboard to  exit \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'): \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpImg = ((255*(changeBlur[0] + abs(np.min(changeBlur[0]))) / \n",
    "np.max(changeBlur[0] + abs(np.min(changeBlur[0])))).astype(\"uint8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Frame', tmpImg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii =30\n",
    "frame = (changeImgs[ii] + 80).astype(\"uint8\")\n",
    "cv2.imshow('Frame', frame) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(changeImgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play video\n",
    "for ii in range(len(changeImgs)):\n",
    "    frame = (changeImgs[ii] + 80).astype(\"uint8\")\n",
    "    \n",
    "    # Display the resulting frame \n",
    "    cv2.imshow('Frame', frame) \n",
    "   \n",
    "    # Press Q on keyboard to  exit \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'): \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate background image\n",
    "# # check dtype\n",
    "#     if calImg.dtype != \"int16\":\n",
    "#         calImg = calImg.astype('int16') \n",
    "#     if frame.dtype != \"int16\":\n",
    "#         frame = frame.astype('int16')\n",
    "    \n",
    "#     # get image difference\n",
    "#     im1Diff = (calImg - frame) \n",
    "#     height,width = im1Diff.shape\n",
    "    \n",
    "#     # crop image to a circle\n",
    "#     mask_circ = np.zeros((height,width), np.uint8)\n",
    "#     cv2.circle(mask_circ,(int(width/2),int(height/2)),int(np.min([width,height])/2),(255),thickness=-1)\n",
    "#     imDiff_cropped = cv2.bitwise_and(im1Diff, im1Diff, mask=mask_circ)\n",
    "\n",
    "#     # gaussian blur\n",
    "#     # 121, 121 works for full sized image, 15,15 works for 4x smaller image\n",
    "#     # 5,5 works for 1/10 size\n",
    "#     blur = cv2.GaussianBlur(imDiff_cropped, blurAmt ,0)\n",
    "    \n",
    "#     # get darker sections (positive threshold gives dark areas)\n",
    "#     ret_dark,th3_dark = cv2.threshold(blur,70,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "#     # get areas\n",
    "#     img, cnts, _ = cv2.findContours(th3_dark.astype('uint8'), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     mask = np.ones(th3_dark.shape[:2], dtype=\"uint8\") * 0 # create a blank black mask\n",
    "\n",
    "#     areas = np.array([cv2.contourArea(c, False) for c in cnts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "opencv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
