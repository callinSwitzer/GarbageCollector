{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rnn import Rnn\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# note: use python2, not 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NameRnn(Rnn):\n",
    "    '''\n",
    "    RNN which learns from a list of names\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        # note default is names.txt, I made names2.txt\n",
    "        super(NameRnn, self).__init__('names2.txt')\n",
    "        self.minimum_name_length = 3\n",
    "        self.maximum_name_length = 7\n",
    "        self.iterations_per_log = 1000\n",
    "\n",
    "    def validate(self,name):\n",
    "        '''Validate that the first char and length are appropriate'''\n",
    "        return (self.is_letter(name[0]) and self.is_acceptable_length(name))\n",
    "\n",
    "    def is_letter(self, character):\n",
    "        return ord(character) in range(65,90)\n",
    "\n",
    "    def is_acceptable_length(self, name):\n",
    "        return self.meets_maximum_length(name) and self.meets_minimum_length(name)\n",
    "\n",
    "    def meets_minimum_length(self, name):\n",
    "        return len(name) >= self.minimum_name_length\n",
    "\n",
    "    def meets_maximum_length(self, name):\n",
    "        return len(name) <= self.maximum_name_length\n",
    "\n",
    "    def get(self,num):\n",
    "        '''Gets a list of generated names'''\n",
    "        names = []\n",
    "        while len(names) < num:\n",
    "            start_char_id = random.randint(0, len(self.char_to_ix)-1)\n",
    "            start = self.ix_to_char[start_char_id]\n",
    "\n",
    "            self.hprev = np.random.randn(len(self.hprev), 1)\n",
    "            sample_ix = self.sample(self.char_to_ix[start], 30, training=False)\n",
    "            txt = ''.join(self.ix_to_char[ix] for ix in sample_ix)\n",
    "\n",
    "            # Clean up\n",
    "            for name in txt.split():\n",
    "                if self.validate(name):\n",
    "                    names.append(name.capitalize())\n",
    "        self.saveParameters()\n",
    "        return names\n",
    "\n",
    "    def print_names(self, rows, columns):\n",
    "        for name in [self.get(columns) for i in range(rows)]:\n",
    "            out = ''\n",
    "            for x in name:\n",
    "                out += x.ljust(15)\n",
    "            print(out)\n",
    "\n",
    "    def step(self,p):\n",
    "        '''Does the heavy lifting'''\n",
    "        smooth_loss = -np.log(1.0/self.vocab_size)*self.seq_length # loss at iteration 0\n",
    "        # prepare inputs (we're sweeping from left to right in steps seq_length long)\n",
    "        if p+self.seq_length+1 >= len(self.data):\n",
    "            self.hprev = np.zeros((self.hidden_size,1)) # reset RNN memory\n",
    "            p = 0 # go from start of data\n",
    "\n",
    "        inputs = [self.char_to_ix[ch] for ch in self.data[p:p+self.seq_length]]\n",
    "        targets = [self.char_to_ix[ch] for ch in self.data[p+1:p+self.seq_length+1]]\n",
    "\n",
    "        # forward seq_length characters through the net and fetch gradient\n",
    "        loss, dWxh, dWhh, dWhy, dbh, dby = self.lossFun(inputs, targets)\n",
    "        smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "\n",
    "        # perform parameter update with Adagrad\n",
    "        for param, dparam, mem in zip([self.Wxh, self.Whh, self.Why, self.bh, self.by],\n",
    "                [dWxh, dWhh, dWhy, dbh, dby],\n",
    "                [self.mWxh, self.mWhh, self.mWhy, self.mbh, self.mby]):\n",
    "            mem += dparam * dparam\n",
    "            param += -self.learning_rate * dparam / np.sqrt(mem + 1e-8) # adagrad update\n",
    "\n",
    "        next_ind = p + self.data[p:p+self.seq_length].index(' ')+1 # move data pointer\n",
    "        #print(self.data[p:next_ind])\n",
    "        return next_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 8193 characters, 28 of which are unique.\n",
      "expected bytes-like object, not str\n"
     ]
    }
   ],
   "source": [
    "x = NameRnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " UD\n",
      "EZO\n",
      "DERE\n",
      "HAPHESTEMBREY\n",
      "JEY\n",
      "JAGELN\n",
      "CLYME\n",
      "HUPO\n",
      "ERRID\n",
      "ERGO\n",
      "NARY\n",
      "CYLOND\n",
      "KAICIO\n",
      "BUBTY\n",
      "PADRNIARD\n",
      "DID\n",
      "BRICE\n",
      "EDRUSSIN\n",
      "RODY\n",
      "ELEZO\n",
      "GARMIQUARCALD\n",
      "KRY\n",
      "CHALMONCY\n",
      "CALCER\n",
      "LUZB\n",
      "ING\n",
      "ARANGE\n",
      "NACHER\n",
      "CURON\n",
      "HENAD\n",
      "JERMEL \n",
      "----\n",
      "0.0% of process completed\n",
      "Training completed.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type 'bytes' is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-dc2ce1f95758>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitRepos\\GarbageCollector\\rnn.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, num_iterations)\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0mn\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;31m# iteration counter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training completed.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaveParameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpercentage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitRepos\\GarbageCollector\\rnn.py\u001b[0m in \u001b[0;36msaveParameters\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;34m'''Saves all weights and biases into a file for continuity'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Wxh'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWxh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Whh'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWhh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Why'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWhy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitRepos\\GarbageCollector\\rnn.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(ndarray)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbase64\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb64encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjsonDump\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m    179\u001b[0m         raise TypeError(\"Object of type '%s' is not JSON serializable\" %\n\u001b[1;32m--> 180\u001b[1;33m                         o.__class__.__name__)\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type 'bytes' is not JSON serializable"
     ]
    }
   ],
   "source": [
    "x.train(num_iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nms = [x.randomSample(28) for f in range(500000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BUCK', 'BUCKAN', 'BUCKD', 'BUCKE', 'BUCKEL', 'BUCKEO', 'BUCKER',\n",
       "       'BUCKERWARL', 'BUCKES', 'BUCKEY', 'BUCKIE', 'BUCKIEN',\n",
       "       'BUCKILINANK', 'BUCKIN', 'BUCKISAN', 'BUCKO', 'BUCKOLEN',\n",
       "       'BUCKRANDEMER', 'BUCKS', 'BUCKY', 'COBBUCK', 'PEBUCK', 'SBUCK'],\n",
       "      dtype='<U12')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll = [ii.splitlines() for ii in nms if \"BUC\" in ii]\n",
    "flattened_list = [y for x in ll for y in x]\n",
    "flattened_list2 = [f for f in flattened_list if \"BUCK\" in f]\n",
    "np.unique(flattened_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['R', 'RADAN', 'RADDY', 'RADIE', 'RAIG', 'RAIGHER', 'RAIN',\n",
       "       'RALEVEMYLER', 'RALPEL', 'RAM', 'RAMANAHENE', 'RANARDAN',\n",
       "       'RANDEVIO', 'RANGROLT', 'RANN', 'RANRAND', 'RARWIL', 'RASSAN',\n",
       "       'RDAVON', 'REAREL', 'REBBY', 'REBIEL', 'REBUCE', 'REDO', 'REFRI',\n",
       "       'REFSED', 'REFUD', 'REGRYL', 'REGURE', 'REID', 'RELIO', 'RENAR',\n",
       "       'RENEBE', 'RENEL', 'RENO', 'REONSEM', 'RESTID', 'REVIEL', 'REVIM',\n",
       "       'REWINOLEY', 'REY', 'REYMAN', 'REYMIN', 'RI', 'RIBUC', 'RICE',\n",
       "       'RICK', 'RICKY', 'RIEFE', 'RIK', 'RILIEBIULLIN', 'RIONBY', 'RKEL',\n",
       "       'RO', 'ROBDO', 'ROBIN', 'ROBON', 'ROBROY', 'ROBUCCHEO', 'ROBUCE',\n",
       "       'ROBUCERTHIABLON', 'ROBUCQUIN', 'RODE', 'RODRA', 'ROEN', 'ROHE',\n",
       "       'ROM', 'ROMAND', 'ROMER', 'ROMEY', 'ROMICCO', 'RON', 'RONGY',\n",
       "       'RONSHEOSINE', 'RORO', 'ROSCE', 'ROSCHER', 'ROSE', 'ROSSANDALDER',\n",
       "       'ROSTON', 'ROY', 'RUBALD', 'RUBEG', 'RUBERUGLUK', 'RUBUCE',\n",
       "       'RUBUCIERY', 'RUCKE', 'RUD', 'RUDAN', 'RUDOLI', 'RUFOR', 'RUSTIAL',\n",
       "       'RWERNI', 'RY', 'RYA', 'RYALEB', 'RYDE', 'RYESTON', 'RYONGO', 'RYOS'],\n",
       "      dtype='<U15')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_list2 = [f for f in flattened_list if f.startswith(\"R\")]\n",
    "np.unique(flattened_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1225"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(flattened_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIT\n",
      "MARKE\n",
      "ARLEL\n",
      "RA\n",
      "NARTON\n",
      "DIERRICL\n",
      "J\n",
      "HIMAN\n",
      "FANAUGHAR\n",
      "R\n",
      "ER\n",
      "TEMAR\n",
      "OUSCODAN\n",
      "E\n",
      "ALMIRCHARS\n",
      "GOUN\n",
      "MARRON\n",
      "ROLE\n",
      "SANT\n",
      "H\n",
      "ISTY\n",
      "SHENNEY\n",
      "ANTY\n",
      "AMMIN\n",
      "DARAS\n",
      "ENG\n",
      "H\n",
      "ANDIALDO\n",
      "CARBY\n",
      "DAR\n",
      "AN\n",
      "EMERNITON\n",
      "JONAN\n",
      "Y\n",
      "TONRY\n",
      "PONIO\n",
      "DENN\n",
      "TANDO\n",
      "MATCHARF\n",
      "RE\n",
      "AIAL\n",
      "JARIC\n",
      "HORON\n",
      "J\n",
      "TRENN\n",
      "CLLOS\n",
      "ERMAA\n",
      "TONTER\n",
      "HENROLFIAC\n",
      "AR\n",
      "STON\n",
      "CELVITHMIC\n",
      "PAMIA\n",
      "LEWISENDAN\n",
      "TANDIN\n",
      "SENE\n",
      "DUIL\n",
      "WINTRIO\n",
      "DARID\n",
      "ROD\n",
      "LEWISTOELIH\n",
      "DARRI\n",
      "TORTE\n",
      "ESWICAR\n",
      "JON\n",
      "O\n",
      "BENCY\n",
      "OSMENE\n",
      "MAV\n",
      "ON\n",
      "RIMON\n",
      "SULON\n",
      "FOU\n",
      "AND\n",
      "SENTON\n",
      "WOON\n",
      "RE\n",
      "ACMARIAK\n",
      "PHARL\n",
      "IGA\n",
      "A\n",
      "SONY\n",
      "STOH\n",
      "NOLLY\n",
      "EWIS\n",
      "BRUCO\n",
      "PARRIOS\n",
      "SON\n",
      "EDWIST\n",
      "MOCITR\n",
      "E\n",
      "DEGETHONE\n",
      "ELEX\n",
      "E\n",
      "JOSMO\n",
      "ES\n",
      "LEWIS\n",
      "AM\n",
      "EFFORE\n",
      "SSADE\n",
      "MICRI\n",
      "LIN\n",
      "MALILON\n",
      "BRACU\n",
      "NOVELFRED\n",
      "CORTAN\n",
      "INCO\n",
      "MORT\n",
      "JERE\n",
      "IST\n",
      "US\n",
      "SYNLYL\n",
      "SERENTON\n",
      "DEAN\n",
      "ONAND\n",
      "GIVIS\n",
      "OBAN\n",
      "ROGLACH\n",
      "ESRON\n",
      "IN\n",
      "FREDOYMUNDO\n",
      "MAG\n",
      "MARCCORTIE\n",
      "KREYNE\n",
      "CARIO\n",
      "WAMARNE\n",
      "STIS\n",
      "ALVIN\n",
      "CELLON\n",
      "AHIAS\n",
      "ELL\n",
      "JEAN\n",
      "EFFERNEL\n",
      "DALVITIA\n",
      "DONNY\n",
      "CE\n",
      "ANT\n",
      "HINANCER\n",
      "JEDVA\n",
      "ILBOIS\n",
      "MOTHERARO\n",
      "OHNOTJAIN\n",
      "SSANCE\n",
      "A\n",
      "ARLON\n",
      "GELL\n",
      "EDAM\n",
      "NA\n",
      "A\n",
      "KIALAN\n",
      "VASEAY\n",
      "JE\n",
      "AH\n",
      "ELIO\n",
      "LOREL\n",
      "TRY\n",
      "LECHAN\n",
      "HADANUSTOR\n",
      "TAM\n",
      "FORNELON\n",
      "DOSAU\n",
      "DAM\n",
      "TITHRISTOA\n",
      "ROC\n",
      "ONNDO\n",
      "MARAND\n",
      "SILK\n",
      "ASC\n",
      "JANAH\n",
      "HMINE\n",
      "GA\n",
      "EN\n",
      "AUCINARLAN\n",
      "ANDA\n",
      "UR\n",
      "LOAL\n",
      "SOD\n",
      "WALLE\n",
      "E\n",
      "SINTIO\n",
      "GLELROITO\n",
      "OLJORO\n",
      "KENARDAL\n",
      "BL\n",
      "IHOSATHINIER\n",
      "JAROS\n",
      "ACY\n",
      "KAXTON\n",
      "ROSSO\n",
      "D\n",
      "EFEOMENTUEL\n",
      "EYRES\n",
      "AS\n",
      "AUGE\n",
      "LARE\n",
      "MARCE\n",
      "MILE\n",
      "ARTUD\n",
      "DICE\n",
      "A\n",
      "OITT\n",
      "HINUAR\n",
      "SER\n",
      "CU\n",
      "UO\n",
      "ALAEN\n",
      "ROASCOR\n",
      "L\n",
      "LAND\n",
      "CORLINY\n",
      "CHRU\n",
      "EMALIVE\n",
      "FRANCERUC\n",
      "A\n",
      "LOYSCARLANT\n",
      "HUCH\n",
      "EL\n",
      "VIN\n",
      "CLARY\n",
      "DOMAW\n",
      "PARRIE\n",
      "MURCOR\n",
      "ALVI\n",
      "RCOU\n",
      "HONELALD\n",
      "IGHY\n",
      "LIAS\n",
      "CRAIL\n",
      "BARLO\n",
      "LEWONIEN\n",
      "AH\n",
      "GICT\n",
      "IN\n",
      "LAN\n",
      "EDWAIDARIJE\n",
      "RAON\n",
      "KRYLLY\n",
      "OMANCH\n",
      "LANDEN\n",
      "TOBELL\n",
      "BYRE\n",
      "OLY\n",
      "DENNIA\n",
      "DERALA\n",
      "CORTON\n",
      "KUXXONNIAS\n",
      "TONNER\n",
      "BOLDO\n",
      "ARCI\n",
      "TONAY\n",
      "ALPUS\n",
      "TON\n",
      "S\n",
      "OON\n",
      "DERMEE\n",
      "BARDIE\n",
      "Y\n",
      "FRALIE\n",
      "WALDON\n",
      "RO\n",
      "TODDAL\n",
      "DYLL\n",
      "MILLE\n",
      "S\n",
      "ANSANTEL\n",
      "FOLDO\n",
      "M\n",
      "EY\n",
      "JARK\n",
      "HUSTON\n",
      "WIL\n",
      "EORCCHONIIS\n",
      "GARUI\n",
      "KOR\n",
      "BRES\n",
      "REDARTO\n",
      "ALIFFO\n",
      "BARLANNIL\n",
      "YLLEX\n",
      "GENNORVO\n",
      "NAG\n",
      "ORICE\n",
      "BUENES\n",
      "BELBE\n",
      "KURIN\n",
      "DAYANNAR\n",
      "DO\n",
      "KAYNER\n",
      "FORRINED\n",
      "W\n",
      "AN\n",
      "XANDREL\n",
      "JAEVIN\n",
      "GERICAD\n",
      "PETHENE\n",
      "M\n",
      "ON\n",
      "FEWER\n",
      "CORIS\n",
      "ART\n",
      "O\n",
      "RACRANCEL\n",
      "BANMAL\n",
      "HERIBHE\n",
      "BERNY\n",
      "RAL\n",
      "SBARVIN\n",
      "ALFIE\n",
      "MIC\n",
      "DOROND\n",
      "HADRENNALD\n",
      "KEISHALEPHTON\n",
      "JAH\n"
     ]
    }
   ],
   "source": [
    "nlst = []\n",
    "\n",
    "for ii in np.arange(100): \n",
    "    print(x.randomSample(18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Aache'],\n",
       "       ['Aanwas'],\n",
       "       ['Aaron'],\n",
       "       ['Abaet'],\n",
       "       ['Abarden'],\n",
       "       ['Abbadon'],\n",
       "       ['Abbe'],\n",
       "       ['Abbo'],\n",
       "       ['Abe'],\n",
       "       ['Aberbysion']], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = np.array(np.transpose(pd.read_csv(\"names.txt\", sep = \" \", header = None, )))\n",
    "aa[0:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-8dc91b24a2fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;34m\"Ab\"\u001b[0m \u001b[1;32min\u001b[0m  \u001b[0maa\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'aa' is not defined"
     ]
    }
   ],
   "source": [
    "\"Ab\" in  aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in names and output it in the same format as names.txt\n",
    "bb = pd.read_table(\"dist.male.first.txt\", header = None, delimiter=r\"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JAMES</td>\n",
       "      <td>3.318</td>\n",
       "      <td>3.318</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOHN</td>\n",
       "      <td>3.271</td>\n",
       "      <td>6.589</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROBERT</td>\n",
       "      <td>3.143</td>\n",
       "      <td>9.732</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MICHAEL</td>\n",
       "      <td>2.629</td>\n",
       "      <td>12.361</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WILLIAM</td>\n",
       "      <td>2.451</td>\n",
       "      <td>14.812</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1       2  3\n",
       "0    JAMES  3.318   3.318  1\n",
       "1     JOHN  3.271   6.589  2\n",
       "2   ROBERT  3.143   9.732  3\n",
       "3  MICHAEL  2.629  12.361  4\n",
       "4  WILLIAM  2.451  14.812  5"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    JOHN           3.271  6.589      2\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.loc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4102</th>\n",
       "      <th>4103</th>\n",
       "      <th>4104</th>\n",
       "      <th>4105</th>\n",
       "      <th>4106</th>\n",
       "      <th>4107</th>\n",
       "      <th>4108</th>\n",
       "      <th>4109</th>\n",
       "      <th>4110</th>\n",
       "      <th>4111</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aache</td>\n",
       "      <td>Aanwas</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>Abaet</td>\n",
       "      <td>Abarden</td>\n",
       "      <td>Abbadon</td>\n",
       "      <td>Abbe</td>\n",
       "      <td>Abbo</td>\n",
       "      <td>Abe</td>\n",
       "      <td>Aberbysion</td>\n",
       "      <td>...</td>\n",
       "      <td>Woon</td>\n",
       "      <td>Worf</td>\n",
       "      <td>Wotan</td>\n",
       "      <td>Wrall</td>\n",
       "      <td>Wrathran</td>\n",
       "      <td>Wraythe</td>\n",
       "      <td>Wrothag</td>\n",
       "      <td>Wulf</td>\n",
       "      <td>Wulfgrim</td>\n",
       "      <td>Wuthmon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 4112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0       1      2      3        4        5     6     7    8           9     \\\n",
       "0  Aache  Aanwas  Aaron  Abaet  Abarden  Abbadon  Abbe  Abbo  Abe  Aberbysion   \n",
       "\n",
       "    ...     4102  4103   4104   4105      4106     4107     4108  4109  \\\n",
       "0   ...     Woon  Worf  Wotan  Wrall  Wrathran  Wraythe  Wrothag  Wulf   \n",
       "\n",
       "       4110     4111  \n",
       "0  Wulfgrim  Wuthmon  \n",
       "\n",
       "[1 rows x 4112 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"names.txt\", sep = \" \", header = None, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cc = bb.loc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd = pd.DataFrame(cc.values.reshape([1, len(bb)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dd.to_csv(\"names2.txt\", sep = \" \", header = None, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
