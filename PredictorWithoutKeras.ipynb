{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights\n",
    "\n",
    "\n",
    "# write function to make predictions from weights and return intermediate values\n",
    "\n",
    "\n",
    "# double check that my predictions are the same as saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calli\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow successfully installed.\n",
      "The installed version of TensorFlow includes GPU support.\n",
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)] \n",
      "\n",
      "last run on 2019-05-24 14:45:51.657414\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import subprocess\n",
    "import winsound\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow successfully installed.\")\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"The installed version of TensorFlow includes GPU support.\")\n",
    "print(sys.version, \"\\n\")\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))\n",
    "\n",
    "# define directories\n",
    "baseDir = os.getcwd()\n",
    "dataDir = r'D:\\MothSimulations\\11c-AggressiveManeuver\\Qstore\\hws_am_con'\n",
    "figDir = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\Figs'\n",
    "dataOutput = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput'\n",
    "savedModels = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels'\n",
    "randomRawData = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\PythonGeneratedData\\TrainingData'\n",
    "if not os.path.exists(dataOutput):\n",
    "    os.mkdir(dataOutput)\n",
    "if not os.path.exists(savedModels):\n",
    "    os.mkdir(savedModels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "# Keras callcacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.random.rand(100,2 )\n",
    "Y_train = np.random.rand(X_train.shape[0], 1) + np.sum(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "inputs = Input(shape=(X_train.shape[1],))    \n",
    "\n",
    "# add layers\n",
    "x = Dense(3, activation='tanh', )(inputs)\n",
    "x = Dense(3, activation='tanh', )(x)\n",
    "predictions = Dense(Y_train.shape[1], activation='linear')(x)\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer = \"rmsprop\", metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 9         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 12        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 25\n",
      "Trainable params: 25\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " - 0s - loss: 11122.9490 - mean_squared_error: 11122.9490\n",
      "Epoch 2/3\n",
      " - 0s - loss: 11106.4566 - mean_squared_error: 11106.4566\n",
      "Epoch 3/3\n",
      " - 0s - loss: 11094.2870 - mean_squared_error: 11094.2870\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs = 3, verbose = 2, \n",
    "                        batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "# wts\n",
    "\n",
    "# for ii in range(len(wts)):\n",
    "#     print(wts[ii], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.65859145]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[1,2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnLayerValues(weights, inputData):\n",
    "    '''\n",
    "    Returns intermediate layer values from fitted network\n",
    "    \n",
    "    The fitted network uses \"tanh\" activation for hidden layer and\n",
    "        \"linear\" activation for the final layer\n",
    "        \n",
    "    Params:\n",
    "        weights (list): list of weights from a fitted model\n",
    "        inputData (array or Data frame): input data that will be run through the network\n",
    "    \n",
    "    Returns:\n",
    "        layer values (list): values of all of the units in the network.\n",
    "            - the 0'th item in the list is the input data\n",
    "            - the final item in the list is the final prediction\n",
    "    '''\n",
    "    LayerValues = [inputData.astype(\"float64\")]\n",
    "    for layerNum in np.arange(0, len(wts), 2):\n",
    "        \n",
    "        # calculate dot product and add bias\n",
    "        nextLayer = np.dot(LayerValues[-1], wts[layerNum]) + wts[layerNum+1]\n",
    "        \n",
    "        if layerNum != (len(wts)-2):\n",
    "            # apply activation function, except for final layer\n",
    "            nextLayer = np.tanh(nextLayer)\n",
    "        \n",
    "        # append to list\n",
    "        LayerValues.append(nextLayer)\n",
    "        \n",
    "    return(LayerValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function returns values of all layers\n",
    "def returnLayerValues2(weights, inputData):\n",
    "    '''\n",
    "    Returns all layer values from fitted network (including input and output)\n",
    "    \n",
    "    The fitted network uses \"tanh\" activation for hidden layers and\n",
    "        \"linear\" activation for the final layer\n",
    "        \n",
    "    Params:\n",
    "        weights (list): list of weights from a fitted model\n",
    "        inputData (array or Data frame): input data that will be run through the network\n",
    "    \n",
    "    Returns:\n",
    "        layer values (list): values of all of the units in the network.\n",
    "            - the 0'th item in the list is the input data\n",
    "            - the final item in the list is the final prediction\n",
    "    '''\n",
    "    \n",
    "    LayerValues = [inputData.astype(\"float64\")]\n",
    "    for layerNum in np.arange(0, len(wts), 2):\n",
    "        \n",
    "        # this version combines weights and biases into single matrix\n",
    "        nextInput =  np.hstack([np.array([[1]]), LayerValues[-1]])\n",
    "        wts_and_bias = np.vstack([wts[layerNum+1], wts[layerNum]])\n",
    "        \n",
    "        # calculate dot product and add bias\n",
    "        nextLayer = np.dot(nextInput, wts_and_bias)\n",
    "        \n",
    "        if layerNum != (len(wts)-2):\n",
    "            # apply activation function, except for final layer\n",
    "            nextLayer = np.tanh(nextLayer)\n",
    "        \n",
    "        # append to list\n",
    "        LayerValues.append(nextLayer)\n",
    "        \n",
    "    return(LayerValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array([[3,4]])\n",
    "a2 = np.array([[1,2,3],\n",
    "                [-1,4,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1, 22, 29]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(a1, a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 4.5345000e+04,  4.7319666e-01,  1.9255146e-01],\n",
       "        [ 5.4454000e+04,  9.6111172e-01, -4.7174031e-01]], dtype=float32),\n",
       " array([0., 0., 0.]),\n",
       " array([[ 0.        ,  0.        ,  0.        ],\n",
       "        [-0.36316523, -0.05273912,  0.5135607 ],\n",
       "        [ 0.8681359 ,  0.52011275,  0.5968207 ]], dtype=float32),\n",
       " array([0., 0., 0.]),\n",
       " array([[ 0.75470626],\n",
       "        [ 1.0979398 ],\n",
       "        [-0.06574009]], dtype=float32),\n",
       " array([0.])]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wts = model.get_weights().copy()\n",
    "wts\n",
    "\n",
    "wts[0][:, 0] = [45345,54454]\n",
    "wts[1] = np.zeros(wts[1].shape)\n",
    "wts[3] = np.zeros(wts[3].shape)\n",
    "wts[5] = np.zeros(wts[5].shape)\n",
    "wts[2][0,:] = [0,0,0]\n",
    "wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 6., 77.]]),\n",
       " array([[ 1.,  1., -1.]]),\n",
       " array([[-0.84295633, -0.51745063, -0.08306814]]),\n",
       " array([[-1.19885318]])]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "intermediateValues = returnLayerValues(wts, inputData= np.array([[6,77]]))\n",
    "intermediateValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2., 5.]]), array([[0.69387147, 0.90695684]]), array([[0.16874838]])]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediateValues = returnLayerValues(wts, inputData= np.array([[2,5]]))\n",
    "intermediateValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediateValues2 = returnLayerValues2(wts, inputData= np.array([[1,2,3,4,5,6,7,8,9,10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(intermediateValues[-1], intermediateValues2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.10542736e-15,  1.06581410e-14,  1.06581410e-14,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediateValues[-1]-intermediateValues2[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check with actual data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "trainDF = pd.read_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be consistent with other code\n",
    "trainDF.rename(columns={\"x0\" : \"x_0\", \"y0\" : \"y_0\", \"phi0\" : \"phi_0\", \"theta0\" : \"theta_0\", \n",
    "                        \"xf\" : \"x_99\", \"yf\" : \"y_99\", \"phif\" : \"phi_99\", \"thetaf\" : \"theta_99\", \n",
    "                        \"xd0\" : \"x_dot_0\", \"yd0\" : \"y_dot_0\", \"phid0\" : \"phi_dot_0\", \"thetad0\": \"theta_dot_0\", \n",
    "                        \"xdf\" : \"x_dot_99\", \"ydf\": \"y_dot_99\", \"phidf\": \"phi_dot_99\", \"thetadf\": \"theta_dot_99\", \n",
    "                        \"tau0\" : \"tau\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData= np.array([[1,2,3,4,5,6,7,8,9,10]])\n",
    "inputData_bias = np.hstack([np.array([[1]]), np.array([[1,2,3,4,5,6,7,8,9,10]])])\n",
    "\n",
    "wts_bias = np.vstack([wts[1], wts[0]])\n",
    "\n",
    "\n",
    "nextLayer = np.dot(inputData_bias, wts_bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to fx and fy\n",
    "trainDF[\"Fx\"] = trainDF.F * np.cos(trainDF.alpha)\n",
    "trainDF[\"Fy\"] = trainDF.F * np.sin(trainDF.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data \n",
    "scalerX = MinMaxScaler([-0.5, 0.5])  \n",
    "scalerY = MinMaxScaler([-0.5, 0.5])  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNetVisDataPath = r\"D:\\Dropbox\\AcademiaDropbox\\UW\\NNetVisualization\\ExampleData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1239039)\n",
    "sampleInts = np.random.randint(0, Xtrain_scaled.shape[0], size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallX_train = Xtrain_scaled[sampleInts, :]\n",
    "smallY_train = Ytrain_scaled[sampleInts, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "xtsm = pd.DataFrame(smallX_train, columns = X.columns)\n",
    "ytsm = pd.DataFrame(smallY_train, columns = Y.columns)\n",
    "\n",
    "\n",
    "xtsm.to_csv(os.path.join(NNetVisDataPath, \"X_train_small.csv\"), index = False)\n",
    "ytsm.to_csv(os.path.join(NNetVisDataPath, \"Y_train_small.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data and model\n",
    "dpth = r\"D:\\Dropbox\\AcademiaDropbox\\UW\\NNetVisualization\\ExampleData\\Opt_rmsprop__Dro_0.0__Num_20_16__Wei_0.h5\"\n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model(dpth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07868618,  0.05531172, -0.4204175 , ..., -0.2919854 ,\n",
       "         0.01584185,  0.00471532],\n",
       "       [ 0.20772386,  0.17999463, -0.19987795, ...,  0.06676452,\n",
       "        -0.19427305, -0.20139787],\n",
       "       [-0.01532531, -0.5210961 ,  0.44184887, ...,  0.02331303,\n",
       "         0.41064593,  0.40982944],\n",
       "       ...,\n",
       "       [-0.01556098, -0.38132113,  0.35222876, ..., -0.14111082,\n",
       "         0.11535618,  0.11606424],\n",
       "       [-0.30363825, -0.3739403 ,  0.40084484, ...,  0.32999206,\n",
       "         0.08843673,  0.08833369],\n",
       "       [-0.03489161, -0.37062043, -0.4276588 , ..., -0.05476546,\n",
       "        -0.01598368, -0.02264309]], dtype=float32)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wts = model.get_weights().copy()\n",
    "model.predict(xtsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediateValues = returnLayerValues(wts, inputData= xtsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07868646,  0.05531151, -0.42041834, ..., -0.29198529,\n",
       "         0.01584188,  0.00471533],\n",
       "       [ 0.20772348,  0.1799945 , -0.19987852, ...,  0.06676457,\n",
       "        -0.19427305, -0.20139787],\n",
       "       [-0.01532537, -0.52109632,  0.44184895, ...,  0.02331301,\n",
       "         0.41064588,  0.40982945],\n",
       "       ...,\n",
       "       [-0.01556104, -0.38132154,  0.35222881, ..., -0.14111085,\n",
       "         0.11535617,  0.11606422],\n",
       "       [-0.30363825, -0.37394039,  0.40084487, ...,  0.32999208,\n",
       "         0.08843675,  0.08833368],\n",
       "       [-0.03489144, -0.37062073, -0.42765931, ..., -0.05476542,\n",
       "        -0.01598369, -0.0226431 ]])"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediateValues[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = model.predict(xtsm) - intermediateValues[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2758603189787507e-06"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(abs(diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fx              0.206681\n",
       "Fy              0.249421\n",
       "tau             0.129171\n",
       "x_dot_99        0.184459\n",
       "y_dot_99        0.188683\n",
       "phi_dot_99      0.024570\n",
       "theta_dot_99    0.022247\n",
       "dtype: float64"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs = model.predict(xtsm) - ytsm\n",
    "np.max(abs(diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.7913353, 1.6383936, 2.6490834, 1.9456788, 1.945498 , 1.6709379,\n",
       "        1.0960532]], dtype=float32)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return weights from Keras\n",
    "from keras.models import Model\n",
    "\n",
    "inputData = np.array([[1,2,3,4,5,6,7,8,9,10]])\n",
    "\n",
    "layer_name = 'dense_4'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(inputData)\n",
    "intermediate_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52946097]], dtype=float32)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[4.332323, 5.23232]], dtype = \"float64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.891574, 9.837484]], dtype=float32)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputData = np.array([[4,5]])\n",
    "# merge bias and weights matrices\n",
    "LayerValues = []\n",
    "    \n",
    "# add bias to input data\n",
    "inputData = np.hstack([np.array([1], dtype = \"float32\").reshape(-1,1), inputData] )\n",
    "\n",
    "LayerValues.append(inputData)\n",
    "\n",
    "jj = 0\n",
    "\n",
    "wtsConcatenated = [np.vstack([wts[ii + 1], wts[ii]]) for ii in np.arange(0, len(wts), 2)]\n",
    "nextLayer = np.dot(LayerValues[jj], wtsConcatenated[jj]).astype(\"float32\")\n",
    "nextLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00736949],\n",
       "       [1.3782268 ],\n",
       "       [1.347521  ]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii = 2\n",
    "#wts[0] = np.vstack((np.ones(2, dtype = \"float32\"), wts[0]))\n",
    "\n",
    "np.vstack([wts[ii + 1], wts[ii]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtsConcatenated = [np.vstack([wts[ii + 1], wts[ii]]) for ii in np.arange(0, len(wts), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1, 1, 3]])]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returnLayerValues(wts, inputData= np.array([[1,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
