{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights\n",
    "\n",
    "\n",
    "# write function to make predictions from weights and return intermediate values\n",
    "\n",
    "\n",
    "# double check that my predictions are the same as saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow successfully installed.\n",
      "The installed version of TensorFlow includes GPU support.\n",
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)] \n",
      "\n",
      "last run on 2019-05-24 13:27:43.953595\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import subprocess\n",
    "import winsound\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow successfully installed.\")\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"The installed version of TensorFlow includes GPU support.\")\n",
    "print(sys.version, \"\\n\")\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))\n",
    "\n",
    "# define directories\n",
    "baseDir = os.getcwd()\n",
    "dataDir = r'D:\\MothSimulations\\11c-AggressiveManeuver\\Qstore\\hws_am_con'\n",
    "figDir = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\Figs'\n",
    "dataOutput = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput'\n",
    "savedModels = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels'\n",
    "randomRawData = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\PythonGeneratedData\\TrainingData'\n",
    "if not os.path.exists(dataOutput):\n",
    "    os.mkdir(dataOutput)\n",
    "if not os.path.exists(savedModels):\n",
    "    os.mkdir(savedModels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "# Keras callcacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.random.rand(100,10 )\n",
    "Y_train = np.random.rand(X_train.shape[0], 7) + np.sum(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "inputs = Input(shape=(X_train.shape[1],))    \n",
    "\n",
    "# add layers\n",
    "x = Dense(500, activation='tanh', )(inputs)\n",
    "x = Dense(566, activation='tanh')(x)\n",
    "x = Dense(567, activation='tanh')(x)\n",
    "predictions = Dense(Y_train.shape[1], activation='linear')(x)\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss=\"mean_squared_error\", optimizer = \"rmsprop\", metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               5500      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 566)               283566    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 567)               321489    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 3976      \n",
      "=================================================================\n",
      "Total params: 614,531\n",
      "Trainable params: 614,531\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " - 0s - loss: 241342.6794 - mean_squared_error: 241342.6794\n",
      "Epoch 2/3\n",
      " - 0s - loss: 230555.5988 - mean_squared_error: 230555.5988\n",
      "Epoch 3/3\n",
      " - 0s - loss: 225781.2975 - mean_squared_error: 225781.2975\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs = 3, verbose = 2, \n",
    "                        batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "# wts\n",
    "\n",
    "# for ii in range(len(wts)):\n",
    "#     print(wts[ii], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27.963383, 28.111612, 26.493656, 29.12884 , 28.487183, 27.65596 ,\n",
       "        27.848248]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[1,2,3,4,5,6,7,8,9,10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnLayerValues(weights, inputData):\n",
    "    '''\n",
    "    Returns intermediate layer values from fitted network\n",
    "    \n",
    "    The fitted network uses \"tanh\" activation for hidden layer and\n",
    "        \"linear\" activation for the final layer\n",
    "        \n",
    "    Params:\n",
    "        weights (list): list of weights from a fitted model\n",
    "        inputData (array or Data frame): input data that will be run through the network\n",
    "    \n",
    "    Returns:\n",
    "        layer values (list): values of all of the units in the network.\n",
    "            - the 0'th item in the list is the input data\n",
    "            - the final item in the list is the final prediction\n",
    "    '''\n",
    "    LayerValues = [inputData.astype(\"float64\")]\n",
    "    for layerNum in np.arange(0, len(wts), 2):\n",
    "        \n",
    "        # calculate dot product and add bias\n",
    "        nextLayer = np.dot(LayerValues[-1], wts[layerNum]) + wts[layerNum+1]\n",
    "        \n",
    "        if layerNum != (len(wts)-2):\n",
    "            # apply activation function, except for final layer\n",
    "            nextLayer = np.tanh(nextLayer)\n",
    "        \n",
    "        # append to list\n",
    "        LayerValues.append(nextLayer)\n",
    "        \n",
    "    return(LayerValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function returns values of all layers\n",
    "def returnLayerValues2(weights, inputData):\n",
    "    '''\n",
    "    Returns all layer values from fitted network (including input and output)\n",
    "    \n",
    "    The fitted network uses \"tanh\" activation for hidden layers and\n",
    "        \"linear\" activation for the final layer\n",
    "        \n",
    "    Params:\n",
    "        weights (list): list of weights from a fitted model\n",
    "        inputData (array or Data frame): input data that will be run through the network\n",
    "    \n",
    "    Returns:\n",
    "        layer values (list): values of all of the units in the network.\n",
    "            - the 0'th item in the list is the input data\n",
    "            - the final item in the list is the final prediction\n",
    "    '''\n",
    "    \n",
    "    LayerValues = [inputData.astype(\"float64\")]\n",
    "    for layerNum in np.arange(0, len(wts), 2):\n",
    "        \n",
    "        # this version combines weights and biases into single matrix\n",
    "        nextInput =  np.hstack([np.array([[1]]), LayerValues[-1]])\n",
    "        wts_and_bias = np.vstack([wts[layerNum+1], wts[layerNum]])\n",
    "        \n",
    "        # calculate dot product and add bias\n",
    "        nextLayer = np.dot(nextInput, wts_and_bias)\n",
    "        \n",
    "        if layerNum != (len(wts)-2):\n",
    "            # apply activation function, except for final layer\n",
    "            nextLayer = np.tanh(nextLayer)\n",
    "        \n",
    "        # append to list\n",
    "        LayerValues.append(nextLayer)\n",
    "        \n",
    "    return(LayerValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]),\n",
       " array([[-0.95060035,  0.73090569,  0.92555474,  0.93525605,  0.73308881,\n",
       "          0.88345868, -0.72785576, -0.9984618 , -0.7621206 , -0.9573174 ,\n",
       "          0.93519419,  0.99959038,  0.99407362, -0.8817773 ,  0.82130208,\n",
       "         -0.48420636,  0.85414298, -0.56576346, -0.74147101,  0.881499  ,\n",
       "         -0.87751135,  0.92177726, -0.64456637,  0.5513546 ,  0.95861065,\n",
       "          0.9627685 ,  0.99339974, -0.81757951,  0.71999798, -0.98874333,\n",
       "         -0.87184814,  0.89552934, -0.97357109,  0.99380715, -0.85009765,\n",
       "         -0.97386688, -0.99601516, -0.91492469,  0.92087869, -0.98677162,\n",
       "          0.99264342,  0.98230568, -0.88494556,  0.80731088,  0.93940721,\n",
       "          0.93022448, -0.3776354 , -0.95066184,  0.77999077,  0.69470749,\n",
       "         -0.89935773,  0.96824024,  0.27950445,  0.65816965,  0.11427486,\n",
       "          0.85634733,  0.72963965,  0.74392718,  0.98695517, -0.99427107,\n",
       "         -0.15255588,  0.35898409, -0.97414177,  0.39003619, -0.72365516,\n",
       "         -0.97553597, -0.74593457,  0.97429595, -0.57568714,  0.9818457 ,\n",
       "          0.99311824,  0.98279065,  0.99060391,  0.7162726 , -0.87211611,\n",
       "          0.92240126, -0.95437527,  0.96816699,  0.74782613, -0.88777448,\n",
       "          0.81587099,  0.89459273,  0.72021231, -0.82518542,  0.47898824,\n",
       "         -0.8012375 ,  0.98396391,  0.9851815 , -0.7206888 ,  0.7707752 ,\n",
       "          0.98647509,  0.99152864, -0.92495212, -0.96092926,  0.98476298,\n",
       "          0.89527531,  0.77242684,  0.95899227, -0.01471235, -0.99403999,\n",
       "          0.94158326, -0.97696595,  0.98517038, -0.9076908 , -0.79866371,\n",
       "          0.41219913,  0.98230109,  0.98555544, -0.9461546 , -0.97616301,\n",
       "         -0.35624347, -0.17216846,  0.05481567, -0.98340128,  0.8255843 ,\n",
       "          0.99597063, -0.99837453,  0.93649026,  0.99240713,  0.64209755,\n",
       "          0.96648363, -0.99605138,  0.06974072, -0.9932779 , -0.97789275,\n",
       "         -0.77889249, -0.39886018,  0.97141168,  0.89728559,  0.82400004,\n",
       "         -0.69058376,  0.44529548,  0.99171229,  0.56027433,  0.98318863,\n",
       "         -0.87867297,  0.95264487,  0.96552222, -0.45603775,  0.84642917,\n",
       "         -0.12071686, -0.97734321,  0.83567859, -0.74123129,  0.88461078,\n",
       "          0.90720581, -0.3721768 , -0.7855403 ,  0.98094161,  0.70740951,\n",
       "          0.1231458 , -0.77432647, -0.59944754,  0.83400306,  0.49043257,\n",
       "          0.68683324,  0.24757814, -0.82391192, -0.67497916,  0.63952882,\n",
       "         -0.59098602,  0.97900719, -0.40749537, -0.960544  , -0.6681119 ,\n",
       "          0.95485375, -0.97222758,  0.96966344, -0.7724379 , -0.97568255,\n",
       "          0.8710941 ,  0.96620672,  0.70382975, -0.95736428, -0.95204754,\n",
       "          0.83382751, -0.6696561 , -0.84652088, -0.95681752, -0.43788974,\n",
       "          0.90652937,  0.38990458,  0.9933848 ,  0.99497144,  0.58213282,\n",
       "         -0.73661708,  0.95536673,  0.89577856, -0.03913334,  0.71322145,\n",
       "         -0.87660145,  0.79261827, -0.93018544,  0.97065859, -0.76610573,\n",
       "         -0.87304764,  0.99168214, -0.94684835, -0.99548291, -0.8631817 ,\n",
       "          0.99577677,  0.95562807, -0.95948063,  0.9956529 ,  0.86066605,\n",
       "         -0.39574252, -0.96520597, -0.82479315,  0.98554756,  0.96314166,\n",
       "          0.55928865, -0.06504935, -0.86053467, -0.83643366,  0.60104647,\n",
       "          0.96031756,  0.72502838,  0.28590971,  0.90076832, -0.75869016,\n",
       "         -0.23526902,  0.90406691,  0.9396325 , -0.97847586,  0.93960409,\n",
       "          0.98007258, -0.92937426, -0.87563232, -0.75952187,  0.96892887,\n",
       "         -0.98718485, -0.95777786, -0.85355344, -0.99661554, -0.99434705,\n",
       "          0.99126498,  0.96511547, -0.78392196, -0.89208407,  0.7062712 ,\n",
       "         -0.63283651,  0.85491339,  0.98641265, -0.71468908,  0.82933349,\n",
       "         -0.99590124, -0.94761481, -0.89449397,  0.49901364, -0.93339648,\n",
       "          0.90276354,  0.09234204, -0.99127493,  0.96953473, -0.98814619,\n",
       "          0.16746579, -0.90400849, -0.55899757,  0.84596044,  0.58712142,\n",
       "         -0.42786709,  0.97544603, -0.99637876,  0.72134091,  0.95333257,\n",
       "         -0.97390115, -0.97787744, -0.12851027, -0.92910588, -0.98212007,\n",
       "          0.98649586, -0.53013165, -0.07273463,  0.96003179, -0.96213866,\n",
       "          0.93895073, -0.90046713, -0.91634723,  0.97263542,  0.94657138,\n",
       "          0.97283595,  0.92333217,  0.99571391,  0.98654118,  0.13819755,\n",
       "          0.98654151, -0.55427544,  0.80543587, -0.89530319,  0.83758198,\n",
       "         -0.98859514, -0.93765759, -0.89726382,  0.9743156 , -0.57297436,\n",
       "         -0.65563566,  0.97727649,  0.85502256, -0.91077397, -0.74943667,\n",
       "         -0.80578035, -0.7923287 ,  0.70826854,  0.9984913 , -0.59043905,\n",
       "          0.71261634, -0.82808416, -0.06629142, -0.98850756, -0.44291814,\n",
       "          0.80129147,  0.64244245,  0.9678233 ,  0.32844349, -0.67502806,\n",
       "          0.76913974,  0.34201615, -0.93423353,  0.97813978,  0.96755212,\n",
       "         -0.24759714, -0.72921691,  0.91925045, -0.99325808, -0.84213662,\n",
       "          0.64040149,  0.89596867, -0.03109142,  0.38856639, -0.68044194,\n",
       "         -0.25166274,  0.99733151,  0.19706695,  0.82069537, -0.10254699,\n",
       "          0.20484197,  0.26329808, -0.93022279, -0.80054351, -0.33714492,\n",
       "          0.40810712,  0.99798372, -0.98849351,  0.9048251 , -0.98913504,\n",
       "         -0.54169233,  0.95132135, -0.86557566,  0.31375013, -0.59152137,\n",
       "          0.78832308,  0.74889281, -0.99789087, -0.65362581,  0.79027412,\n",
       "          0.60187759,  0.88026181,  0.94241491, -0.26864522,  0.80912196,\n",
       "         -0.99011531, -0.99487548, -0.28922189, -0.92728299,  0.27491302,\n",
       "          0.96929118,  0.96936233, -0.99140732,  0.53585558,  0.99222575,\n",
       "          0.95824815,  0.50434006,  0.78493519,  0.97314159, -0.89296558,\n",
       "          0.83226104,  0.97823066,  0.86635329, -0.74304462, -0.98196816,\n",
       "          0.68903608,  0.65606955, -0.96111882, -0.70400778, -0.9951883 ,\n",
       "         -0.743259  , -0.87140096,  0.54468028,  0.85795105,  0.98530172,\n",
       "          0.9610951 ,  0.94904466, -0.8551158 , -0.98006077,  0.93371379,\n",
       "          0.94666357, -0.96479133,  0.74086649, -0.00667287,  0.95987922,\n",
       "         -0.5367327 , -0.91239401, -0.58356986, -0.96756491,  0.73623391,\n",
       "          0.58894942,  0.81859474, -0.78950538,  0.99866864,  0.83467842,\n",
       "          0.63974188,  0.96282078,  0.99602103, -0.8495799 , -0.94994594,\n",
       "         -0.74736526, -0.92770024, -0.94471169,  0.97773782, -0.41035647,\n",
       "         -0.945989  , -0.31734055, -0.95839091,  0.87621168, -0.82672031,\n",
       "         -0.98262244,  0.00635777,  0.96208338,  0.872824  ,  0.94670301,\n",
       "         -0.28544159, -0.68330312, -0.92255381, -0.99238162, -0.88743124,\n",
       "         -0.88267694,  0.16071793, -0.99030746, -0.87758747, -0.99808738,\n",
       "          0.96289944, -0.94538031,  0.99919044,  0.85947241,  0.96449891,\n",
       "         -0.79109313,  0.85711451, -0.98568031,  0.83595312, -0.8510256 ,\n",
       "         -0.66724942, -0.68480694,  0.67311846, -0.4338192 , -0.74555055,\n",
       "          0.97279027, -0.73695993,  0.98464694,  0.72535228,  0.9786533 ,\n",
       "         -0.27184115, -0.37336444, -0.98885572,  0.05764843, -0.91926137,\n",
       "          0.18202773,  0.99190181, -0.9771109 ,  0.92995209, -0.93838183,\n",
       "         -0.98237915, -0.99442722,  0.84481078, -0.88795563, -0.97740802,\n",
       "          0.89737641,  0.97709284,  0.97922489,  0.72387921,  0.88701729,\n",
       "          0.9792076 , -0.98197544, -0.55440204, -0.40261037,  0.73419874,\n",
       "          0.90793114,  0.96729085,  0.89309666, -0.6813733 , -0.99073477,\n",
       "          0.92479658, -0.99780169, -0.58341897, -0.84894577, -0.97867153,\n",
       "          0.92408894, -0.92280334, -0.79620558, -0.99278069,  0.49716636]]),\n",
       " array([[ 0.52472858, -0.99912765, -0.99994386,  0.99997512,  0.06962132,\n",
       "          0.99997647, -0.99984844, -0.99108051, -0.78032457, -0.99986615,\n",
       "          0.98093995,  0.99966098, -0.99125815, -0.99996497,  0.99343887,\n",
       "          0.99995726, -0.99964091,  0.99402081,  0.99984138,  0.82201778,\n",
       "         -0.99998086,  0.9978721 ,  0.99986398, -0.99972133,  0.97166477,\n",
       "          0.99578335,  0.96174561, -0.99998958,  0.99930835,  0.99998105,\n",
       "         -0.99986841, -0.99995865,  0.99994899, -0.99975622,  0.98847317,\n",
       "          0.9999731 ,  0.99941738,  0.99996845, -0.99994242,  0.99983986,\n",
       "          0.99996338, -0.99998059,  0.9998404 , -0.9997506 ,  0.99996877,\n",
       "         -0.99992335, -0.99922438, -0.9996662 , -0.99671884,  0.99998021,\n",
       "          0.99729131, -0.99970288, -0.96416368, -0.9998567 , -0.5549577 ,\n",
       "          0.94779546, -0.99994753,  0.99997016,  0.98927877, -0.99994608,\n",
       "         -0.99997601,  0.9583158 , -0.99977654,  0.99968483, -0.99990739,\n",
       "         -0.99991118,  0.99864397,  0.99997064, -0.91079782, -0.99998408,\n",
       "         -0.99732486,  0.99996293, -0.99987542, -0.92858739,  0.9999853 ,\n",
       "         -0.98894829,  0.99998204,  0.99909169,  0.85791186,  0.99993483,\n",
       "         -0.98529286, -0.99986805, -0.95853722,  0.99539232, -0.99392838,\n",
       "         -0.99981965, -0.9995374 ,  0.95754522,  0.99995708, -0.98338712,\n",
       "         -0.99991247, -0.99983546,  0.99995632, -0.15430079, -0.99991828,\n",
       "          0.99979797, -0.78228434, -0.99996459, -0.96779469, -0.9999892 ,\n",
       "         -0.99890412,  0.99998876, -0.6956078 , -0.99996818, -0.99997001,\n",
       "          0.99991096,  0.99997862, -0.99991816,  0.99997097, -0.99996519,\n",
       "         -0.99994197,  0.99981101, -0.97645654, -0.99962665, -0.99974203,\n",
       "          0.97327717,  0.99999251, -0.08258363, -0.99628975,  0.99944416,\n",
       "          0.99993032, -0.99960471,  0.94863065, -0.99982825,  0.99998358,\n",
       "          0.99981376, -0.99995062,  0.99803143, -0.99806896,  0.99856989,\n",
       "         -0.99912656, -0.99013538,  0.9903079 ,  0.99992696, -0.99625058,\n",
       "          0.29220181, -0.99980141, -0.99443357, -0.76730784,  0.99986797,\n",
       "          0.99047314, -0.96596289,  0.99623754,  0.99967035, -0.99980948,\n",
       "         -0.9923904 ,  0.83025126, -0.99961833, -0.99996236,  0.99996867,\n",
       "         -0.99987993,  0.99950673, -0.2635377 ,  0.99995641,  0.99529139,\n",
       "         -0.99996783,  0.99887354,  0.98999122, -0.99580363, -0.99991677,\n",
       "          0.96082906, -0.9997454 , -0.9999548 , -0.7553779 ,  0.9998354 ,\n",
       "         -0.99984722,  0.99659003, -0.99951845, -0.99793469,  0.99668986,\n",
       "         -0.99605226,  0.99952957,  0.99992033,  0.99996979,  0.99145927,\n",
       "         -0.99634963, -0.99998061, -0.99998075, -0.99995591,  0.99985762,\n",
       "          0.99919852,  0.99981654, -0.99994423, -0.99993439, -0.9999721 ,\n",
       "          0.99223417, -0.9999744 ,  0.99955279, -0.98764689, -0.9998535 ,\n",
       "         -0.99998016,  0.99936825,  0.99999782,  0.99656246, -0.74367484,\n",
       "          0.90945912,  0.98531142, -0.62106179,  0.98525531, -0.85128444,\n",
       "          0.99994141,  0.20465373, -0.99713076,  0.99920141,  0.99999347,\n",
       "          0.99659311,  0.99430248, -0.99993821, -0.99997421,  0.62215418,\n",
       "          0.98780552,  0.97585601,  0.9628746 ,  0.99998184, -0.99995086,\n",
       "          0.99879187,  0.9999371 , -0.69016778,  0.99999397,  0.9896108 ,\n",
       "         -0.99769285,  0.99965991,  0.99731386, -0.99998266, -0.99898129,\n",
       "         -0.99800141,  0.99998919, -0.83990505, -0.99998691,  0.66218452,\n",
       "         -0.99993587, -0.99999546,  0.9999605 ,  0.99753039,  0.99941518,\n",
       "          0.99935575,  0.99991502,  0.98567119, -0.99987095, -0.99991102,\n",
       "          0.16166169,  0.9623436 ,  0.99986974,  0.99998213, -0.945816  ,\n",
       "         -0.9999665 , -0.99989331, -0.99925022, -0.99981765, -0.99980594,\n",
       "          0.99929086,  0.9889692 , -0.99840836,  0.99998259, -0.99980486,\n",
       "         -0.99996027,  0.96661967,  0.99970725, -0.9999548 ,  0.99991133,\n",
       "         -0.99997538, -0.99983752, -0.99991605,  0.99996068,  0.99984319,\n",
       "         -0.99828635, -0.9999413 , -0.99998587, -0.99997203,  0.99998658,\n",
       "          0.66662195,  0.99980973,  0.99817236, -0.99803966, -0.99966215,\n",
       "          0.99996283,  0.99208646,  0.99992783, -0.99998161, -0.99901467,\n",
       "          0.99982011,  0.99984112,  0.99996638, -0.99830599, -0.97406316,\n",
       "          0.31139498, -0.99995717, -0.99988728, -0.99400699, -0.99993913,\n",
       "          0.53852218,  0.98389367,  0.95518929, -0.99999243, -0.97813575,\n",
       "         -0.99994524,  0.99875124, -0.9996697 ,  0.93085064, -0.26389793,\n",
       "         -0.99995856,  0.99991587,  0.99996084,  0.99997412,  0.99635514,\n",
       "          0.99904321, -0.99452101,  0.99839786,  0.99992015,  0.99960438,\n",
       "          0.99975709, -0.99991037,  0.99996371,  0.78888282,  0.99830991,\n",
       "          0.99998921, -0.99166164, -0.98562588, -0.99995037, -0.99997683,\n",
       "         -0.99928113, -0.99988311, -0.99996969,  0.99996284, -0.99998217,\n",
       "          0.96043224, -0.19598195, -0.99993593,  0.99806113, -0.99996772,\n",
       "          0.99997108,  0.99939008,  0.97738111,  0.99992376, -0.99308386,\n",
       "         -0.83657915,  0.99999212,  0.30257762,  0.99979951, -0.99978195,\n",
       "         -0.9998067 ,  0.99996781,  0.99882412,  0.99964742,  0.99998809,\n",
       "          0.99999053,  0.2978275 ,  0.99998801, -0.87417372,  0.99400063,\n",
       "         -0.99578421,  0.99991526, -0.99964574, -0.99696956,  0.99244201,\n",
       "         -0.96231372,  0.99997516, -0.99540449, -0.9999482 ,  0.99681005,\n",
       "          0.90660849, -0.99968634, -0.99995917,  0.99992746,  0.99991999,\n",
       "          0.99984761, -0.58431541, -0.97231442, -0.99882439,  0.99956481,\n",
       "         -0.40035822, -0.9967252 ,  0.99890679,  0.96918559,  0.87928822,\n",
       "         -0.99994934, -0.9999767 , -0.99856926, -0.03060956,  0.27717374,\n",
       "          0.98795967, -0.99994428, -0.99708255, -0.99990216,  0.96542816,\n",
       "          0.52477239, -0.99862982, -0.99687818,  0.99990888, -0.84396359,\n",
       "         -0.99996185,  0.44245037,  0.93279441, -0.99969831,  0.99998297,\n",
       "          0.99996468, -0.99993783,  0.99943449, -0.8223415 , -0.99959099,\n",
       "         -0.79718859,  0.9720918 ,  0.99992336,  0.99694418,  0.99945795,\n",
       "          0.99289865, -0.99996796,  0.99994493, -0.99933744,  0.99946302,\n",
       "         -0.99940689, -0.99975225,  0.99848413, -0.99998419,  0.99047727,\n",
       "          0.99998674, -0.99995855, -0.99996563, -0.99787438,  0.99987235,\n",
       "         -0.99964827, -0.98822147,  0.99991456, -0.99989361,  0.99166627,\n",
       "          0.98442419, -0.62046798,  0.99971967, -0.99994109, -0.99845131,\n",
       "         -0.99999236, -0.99824817, -0.9999469 , -0.99998426, -0.99488502,\n",
       "          0.99996513,  0.77827599, -0.99681936,  0.72080499,  0.99892555,\n",
       "          0.99891894,  0.9900942 , -0.97454471,  0.99641382, -0.99943186,\n",
       "          0.99763928, -0.99992177,  0.99532573, -0.99918165, -0.99992038,\n",
       "         -0.99997061, -0.99590214,  0.99362095, -0.99997275,  0.9251713 ,\n",
       "          0.99994126, -0.58038751,  0.99998369, -0.99993804,  0.99996378,\n",
       "         -0.74226792, -0.97327488, -0.99944076,  0.99787125, -0.99998697,\n",
       "         -0.99992643,  0.9663035 , -0.99990453,  0.99985486, -0.99994105,\n",
       "          0.99994726,  0.60563756,  0.99994776,  0.92918735,  0.99985121,\n",
       "         -0.9806446 , -0.99994974, -0.80804041, -0.99981121, -0.99548362,\n",
       "         -0.42992261,  0.99999151, -0.98456434, -0.99288585,  0.94650657,\n",
       "          0.73542642, -0.99790128,  0.96083956, -0.99943361, -0.43843884,\n",
       "         -0.9999614 ,  0.99959058,  0.9995837 ,  0.99990868, -0.98336045,\n",
       "         -0.99753645, -0.34654382,  0.99953867, -0.99794545,  0.99803097,\n",
       "          0.99986788,  0.99955911,  0.99990796,  0.99987571, -0.99990333,\n",
       "         -0.99995476, -0.99984216, -0.99998788, -0.99999371,  0.39370308,\n",
       "         -0.9170228 , -0.99996957,  0.99998541,  0.99995667, -0.93498537,\n",
       "          0.99875869, -0.999976  , -0.80533991, -0.99995502,  0.99998831,\n",
       "          0.90029769, -0.99966204, -0.99953673, -0.99765192, -0.99997084,\n",
       "          0.99914394,  0.99995695, -0.32113117, -0.55874369, -0.98461591,\n",
       "         -0.99999081,  0.99989561, -0.99995082,  0.95922116, -0.99992309,\n",
       "         -0.91838818, -0.99990795,  0.99521457,  0.98319535, -0.99988995,\n",
       "         -0.99986624, -0.06893879, -0.92202495, -0.99996977, -0.99980954,\n",
       "         -0.99979991,  0.99982721,  0.98578746, -0.99994207,  0.99997737,\n",
       "         -0.99995372, -0.92383519, -0.49103666,  0.9969954 ,  0.99993926,\n",
       "         -0.99727052,  0.99998071,  0.49128709,  0.99238806, -0.97615145,\n",
       "          0.99976445,  0.99885199, -0.9999825 ,  0.99989882,  0.99990617,\n",
       "          0.99987269]]),\n",
       " array([[-0.99998545, -0.99997495,  0.99997416, -0.99998686,  0.99999616,\n",
       "         -0.99999729,  0.99996779,  0.99999593, -0.99998948, -0.99999537,\n",
       "          0.99998822,  0.99998784,  0.99998942, -0.99999824, -0.99998729,\n",
       "         -0.99999528, -0.99999056, -0.99999461,  0.9999921 , -0.99997741,\n",
       "          0.9999931 , -0.99999736, -0.99998502,  0.99996782, -0.99998972,\n",
       "          0.99999301, -0.9999864 , -0.99999958, -0.99999922,  0.9999687 ,\n",
       "         -0.99995396,  0.99997671,  0.99999637, -0.99999126,  0.99999393,\n",
       "         -0.99997856, -0.99999675, -0.99998636,  0.99997983, -0.99997436,\n",
       "          0.99998867,  0.99997709,  0.99995614,  0.99999551, -0.99999376,\n",
       "          0.99998106,  0.99999125, -0.99997727,  0.9999874 ,  0.99999194,\n",
       "          0.99999664, -0.99997349, -0.99997288,  0.99998188,  0.99999545,\n",
       "         -0.99998205, -0.99998753,  0.99999215,  0.99999637,  0.99999868,\n",
       "          0.99997823, -0.99998261, -0.99999494, -0.99997212,  0.99997284,\n",
       "         -0.99999876,  0.99998749, -0.99999336,  0.99999372, -0.99999044,\n",
       "         -0.99998651,  0.99999137, -0.99999508,  0.99999783,  0.99999411,\n",
       "         -0.99999425, -0.99997562,  0.99998917, -0.99999898,  0.99999567,\n",
       "          0.99997739,  0.99997855, -0.99997064, -0.9999853 ,  0.99997432,\n",
       "         -0.99998557, -0.99999568,  0.99999132,  0.999999  , -0.99999185,\n",
       "         -0.99999364, -0.99999795, -0.99999245,  0.99998481, -0.999994  ,\n",
       "         -0.99996993, -0.99999362,  0.99999948, -0.99998754, -0.99999108,\n",
       "          0.99998792, -0.99996278,  0.99999157,  0.99999228, -0.99998622,\n",
       "          0.99995447, -0.99996394,  0.9999919 ,  0.99994927, -0.999997  ,\n",
       "          0.999997  , -0.99997186,  0.99999795, -0.99999329,  0.9999917 ,\n",
       "         -0.99999632, -0.99999157, -0.99999645,  0.99999734, -0.99998501,\n",
       "         -0.99997199,  0.99999561,  0.99998736, -0.99999469, -0.99998517,\n",
       "         -0.9999917 , -0.99999506,  0.99997189, -0.99997082, -0.99998927,\n",
       "          0.99998886, -0.99999731,  0.99997795,  0.99996755, -0.99999528,\n",
       "         -0.99993935, -0.99998833, -0.99999487,  0.99999287,  0.99999581,\n",
       "          0.99998419, -0.99999833,  0.99997601, -0.99998911, -0.99997636,\n",
       "         -0.99997387,  0.99997071,  0.99999162,  0.99993373,  0.99997268,\n",
       "          0.99994092, -0.99999649, -0.99998672,  0.99999199, -0.99996348,\n",
       "         -0.99996448,  0.99996958,  0.99999288, -0.99999665, -0.99999014,\n",
       "         -0.99997747,  0.9999658 , -0.99999249, -0.99999482,  0.99998931,\n",
       "         -0.99998409,  0.9999745 ,  0.99994812,  0.99998618,  0.99997049,\n",
       "         -0.99998416, -0.99998218,  0.99998141, -0.99993971,  0.99997658,\n",
       "         -0.99999367,  0.99998883,  0.99998946,  0.99994791, -0.99998482,\n",
       "          0.99997608, -0.99998351, -0.99999905, -0.99999449, -0.99998521,\n",
       "         -0.99997742, -0.99999858,  0.99999456, -0.9999946 , -0.99998391,\n",
       "          0.99999206,  0.99998425,  0.99999691,  0.99999877,  0.9999398 ,\n",
       "          0.9999817 , -0.99999775, -0.99999803,  0.99998822, -0.99998358,\n",
       "         -0.99999335,  0.99999614, -0.99997942,  0.99997685, -0.99996731,\n",
       "          0.99998671, -0.99999785, -0.99999288, -0.99999644, -0.99998242,\n",
       "         -0.99999305, -0.99999304, -0.99997239,  0.99998789, -0.99998671,\n",
       "          0.99998791, -0.99998838, -0.99998291, -0.99998838, -0.9999868 ,\n",
       "         -0.99999174,  0.99998962, -0.99999235,  0.99998746, -0.9999877 ,\n",
       "         -0.99998664,  0.99998587, -0.99996921, -0.99999841,  0.99998187,\n",
       "         -0.99999419,  0.99999837,  0.99999664,  0.99998369,  0.99999661,\n",
       "         -0.99998136,  0.99998964, -0.99996868, -0.99999951, -0.9999872 ,\n",
       "         -0.99998664, -0.99997697,  0.99999324,  0.99997292,  0.99999622,\n",
       "          0.9999958 ,  0.99999845, -0.99998801,  0.99998981,  0.9999817 ,\n",
       "          0.99999505, -0.999995  , -0.99993441,  0.99999286, -0.99999606,\n",
       "          0.99997243, -0.99998082,  0.99997378, -0.99996843,  0.99999349,\n",
       "         -0.99997745,  0.99998372,  0.99997656,  0.99998989,  0.99999435,\n",
       "         -0.99999138, -0.9999945 , -0.99999253,  0.99999203,  0.99998102,\n",
       "         -0.99998177, -0.99998418, -0.99995728, -0.99997574, -0.99997864,\n",
       "         -0.99999074,  0.99998892,  0.99998755,  0.99998688,  0.99998593,\n",
       "         -0.99999881, -0.99999491, -0.99994524,  0.99999399, -0.99999658,\n",
       "         -0.99995811, -0.99999512,  0.99999025,  0.99998641, -0.99999209,\n",
       "         -0.99999649,  0.99997643,  0.99998589,  0.999974  ,  0.99998179,\n",
       "          0.99999595,  0.99997937, -0.99998784, -0.99999641,  0.99998583,\n",
       "          0.99997363, -0.99994211,  0.99999739, -0.99995497, -0.99999741,\n",
       "         -0.99996934, -0.99999573, -0.99997962,  0.99999247, -0.99999365,\n",
       "         -0.99997441,  0.99997618,  0.9999946 , -0.99999535,  0.9999968 ,\n",
       "          0.99998893,  0.99999774, -0.99998946, -0.9999976 , -0.99996933,\n",
       "          0.9999925 , -0.99998106,  0.99998704, -0.99998576, -0.99999871,\n",
       "          0.99997855,  0.99998736, -0.99999469,  0.99994747, -0.99998578,\n",
       "          0.99997187, -0.99999845, -0.99998942, -0.99999518, -0.99998797,\n",
       "          0.9999781 ,  0.99999792,  0.99997469, -0.99995492,  0.99999067,\n",
       "          0.99999396, -0.99997937, -0.9999923 ,  0.99999894, -0.99999786,\n",
       "          0.99999137,  0.9999978 ,  0.99998969,  0.99999296,  0.99996651,\n",
       "          0.99999564,  0.99999164,  0.99999049, -0.99999327,  0.99999475,\n",
       "         -0.99999261,  0.99995636,  0.99993076,  0.99999162, -0.99998343,\n",
       "         -0.99999401,  0.99998342,  0.99998588,  0.99998995, -0.99999079,\n",
       "          0.99998087, -0.99996621,  0.99999006,  0.99999281, -0.99997266,\n",
       "          0.99996756, -0.99999773,  0.99998328, -0.99997747,  0.99999159,\n",
       "         -0.99996402,  0.99999149, -0.99995587, -0.99999268,  0.99999626,\n",
       "          0.99999031, -0.99998813,  0.99999767, -0.99997281, -0.9999896 ,\n",
       "          0.9999957 ,  0.99997438,  0.9999934 ,  0.99993592,  0.99998944,\n",
       "          0.99995123, -0.99998827,  0.99997636,  0.99997478,  0.99999971,\n",
       "          0.99999397,  0.99999683,  0.99999649,  0.99999451, -0.99999202,\n",
       "         -0.99998925, -0.99998755, -0.99999839, -0.99995165,  0.99999263,\n",
       "         -0.99999445, -0.99999004,  0.99999374, -0.99997929,  0.99999931,\n",
       "         -0.99999202, -0.99998681, -0.99997771, -0.99999554, -0.99995196,\n",
       "         -0.99997694,  0.99999785,  0.99999505, -0.99999777, -0.99998533,\n",
       "          0.99997816, -0.99998969,  0.99998786,  0.99998159, -0.99999644,\n",
       "          0.99999794,  0.99999731,  0.99997253,  0.99999055, -0.99998761,\n",
       "          0.99997945, -0.99999705,  0.99998697, -0.9999934 , -0.99998186,\n",
       "          0.99998536, -0.99999506,  0.99998039,  0.99999562, -0.99999455,\n",
       "         -0.9999864 ,  0.99999035,  0.99998983,  0.99999088,  0.9999873 ,\n",
       "          0.99998657,  0.99990627, -0.99999735,  0.99997583, -0.99996335,\n",
       "          0.99997238, -0.99999412, -0.99999493,  0.9999902 ,  0.9999935 ,\n",
       "          0.99999366, -0.99998102, -0.99999918, -0.99999239,  0.99998204,\n",
       "         -0.99999755, -0.99999472,  0.99998435,  0.99999616,  0.99998701,\n",
       "         -0.99998235, -0.99999091,  0.99999803,  0.9999845 , -0.99999177,\n",
       "         -0.99999701, -0.99999708, -0.99998643,  0.99999858,  0.99998792,\n",
       "          0.99999276, -0.99999681, -0.99997948,  0.99998093, -0.99996983,\n",
       "          0.99997655, -0.99999532,  0.9999959 ,  0.99996193, -0.99999752,\n",
       "          0.99999644, -0.99996083,  0.99998727, -0.99999045,  0.99999452,\n",
       "          0.99996798,  0.99998026, -0.99997478, -0.99999146, -0.99998794,\n",
       "          0.99999406, -0.99996116, -0.99996382, -0.99999208,  0.99999055,\n",
       "         -0.99998581,  0.99998151, -0.99999376, -0.99998544,  0.99998734,\n",
       "         -0.999985  , -0.99999382, -0.9999948 , -0.99998631,  0.99999904,\n",
       "         -0.99999147, -0.99997604,  0.99998471,  0.99999226,  0.99997139,\n",
       "         -0.99998455, -0.99996923,  0.99999582,  0.99999077,  0.99999526,\n",
       "         -0.99998198, -0.99998513,  0.99999565, -0.99998426,  0.99999765,\n",
       "         -0.99999606,  0.99999276,  0.9999803 ,  0.99998967,  0.99999769,\n",
       "          0.9999935 , -0.99998609,  0.99999012, -0.99999465, -0.99999216,\n",
       "         -0.99998641,  0.99999759, -0.99999863,  0.99999114,  0.99998374,\n",
       "          0.99998961,  0.9999983 ,  0.99994825, -0.99998657,  0.99999037,\n",
       "         -0.99999169,  0.99997473, -0.99997689,  0.99998663,  0.999994  ,\n",
       "         -0.99998387,  0.99997814, -0.99999526, -0.99997789,  0.99999062,\n",
       "          0.99998833,  0.99997848, -0.99999004, -0.99999703, -0.99999535,\n",
       "         -0.99999583,  0.99997412,  0.99999635, -0.99999788, -0.99999214,\n",
       "         -0.99999627, -0.99998114]]),\n",
       " array([[27.96338451, 28.1116062 , 26.49365249, 29.12884013, 28.48718591,\n",
       "         27.65595843, 27.84824786]])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wts = model.get_weights().copy()\n",
    "intermediateValues = returnLayerValues(wts, inputData= np.array([[1,2,3,4,5,6,7,8,9,10]]))\n",
    "intermediateValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediateValues2 = returnLayerValues2(wts, inputData= np.array([[1,2,3,4,5,6,7,8,9,10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(intermediateValues[-1], intermediateValues2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.10542736e-15,  1.06581410e-14,  1.06581410e-14,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediateValues[-1]-intermediateValues2[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check with actual data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "trainDF = pd.read_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be consistent with other code\n",
    "trainDF.rename(columns={\"x0\" : \"x_0\", \"y0\" : \"y_0\", \"phi0\" : \"phi_0\", \"theta0\" : \"theta_0\", \n",
    "                        \"xf\" : \"x_99\", \"yf\" : \"y_99\", \"phif\" : \"phi_99\", \"thetaf\" : \"theta_99\", \n",
    "                        \"xd0\" : \"x_dot_0\", \"yd0\" : \"y_dot_0\", \"phid0\" : \"phi_dot_0\", \"thetad0\": \"theta_dot_0\", \n",
    "                        \"xdf\" : \"x_dot_99\", \"ydf\": \"y_dot_99\", \"phidf\": \"phi_dot_99\", \"thetadf\": \"theta_dot_99\", \n",
    "                        \"tau0\" : \"tau\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData= np.array([[1,2,3,4,5,6,7,8,9,10]])\n",
    "inputData_bias = np.hstack([np.array([[1]]), np.array([[1,2,3,4,5,6,7,8,9,10]])])\n",
    "\n",
    "wts_bias = np.vstack([wts[1], wts[0]])\n",
    "\n",
    "\n",
    "nextLayer = np.dot(inputData_bias, wts_bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to fx and fy\n",
    "trainDF[\"Fx\"] = trainDF.F * np.cos(trainDF.alpha)\n",
    "trainDF[\"Fy\"] = trainDF.F * np.sin(trainDF.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data \n",
    "scalerX = MinMaxScaler([-0.5, 0.5])  \n",
    "scalerY = MinMaxScaler([-0.5, 0.5])  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "NNetVisDataPath = r\"D:\\Dropbox\\AcademiaDropbox\\UW\\NNetVisualization\\ExampleData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1239039)\n",
    "sampleInts = np.random.randint(0, Xtrain_scaled.shape[0], size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallX_train = Xtrain_scaled[sampleInts, :]\n",
    "smallY_train = Ytrain_scaled[sampleInts, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "xtsm = pd.DataFrame(smallX_train, columns = X.columns)\n",
    "ytsm = pd.DataFrame(smallY_train, columns = Y.columns)\n",
    "\n",
    "\n",
    "xtsm.to_csv(os.path.join(NNetVisDataPath, \"X_train_small.csv\"), index = False)\n",
    "ytsm.to_csv(os.path.join(NNetVisDataPath, \"Y_train_small.csv\"), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data and model\n",
    "dpth = r\"D:\\Dropbox\\AcademiaDropbox\\UW\\NNetVisualization\\ExampleData\\Opt_rmsprop__Dro_0.0__Num_20_16__Wei_0.h5\"\n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model(dpth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07868618,  0.05531172, -0.4204175 , ..., -0.2919854 ,\n",
       "         0.01584185,  0.00471532],\n",
       "       [ 0.20772386,  0.17999463, -0.19987795, ...,  0.06676452,\n",
       "        -0.19427305, -0.20139787],\n",
       "       [-0.01532531, -0.5210961 ,  0.44184887, ...,  0.02331303,\n",
       "         0.41064593,  0.40982944],\n",
       "       ...,\n",
       "       [-0.01556098, -0.38132113,  0.35222876, ..., -0.14111082,\n",
       "         0.11535618,  0.11606424],\n",
       "       [-0.30363825, -0.3739403 ,  0.40084484, ...,  0.32999206,\n",
       "         0.08843673,  0.08833369],\n",
       "       [-0.03489161, -0.37062043, -0.4276588 , ..., -0.05476546,\n",
       "        -0.01598368, -0.02264309]], dtype=float32)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wts = model.get_weights().copy()\n",
    "model.predict(xtsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediateValues = returnLayerValues(wts, inputData= xtsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07868646,  0.05531151, -0.42041834, ..., -0.29198529,\n",
       "         0.01584188,  0.00471533],\n",
       "       [ 0.20772348,  0.1799945 , -0.19987852, ...,  0.06676457,\n",
       "        -0.19427305, -0.20139787],\n",
       "       [-0.01532537, -0.52109632,  0.44184895, ...,  0.02331301,\n",
       "         0.41064588,  0.40982945],\n",
       "       ...,\n",
       "       [-0.01556104, -0.38132154,  0.35222881, ..., -0.14111085,\n",
       "         0.11535617,  0.11606422],\n",
       "       [-0.30363825, -0.37394039,  0.40084487, ...,  0.32999208,\n",
       "         0.08843675,  0.08833368],\n",
       "       [-0.03489144, -0.37062073, -0.42765931, ..., -0.05476542,\n",
       "        -0.01598369, -0.0226431 ]])"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediateValues[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = model.predict(xtsm) - intermediateValues[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2758603189787507e-06"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(abs(diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fx              0.206681\n",
       "Fy              0.249421\n",
       "tau             0.129171\n",
       "x_dot_99        0.184459\n",
       "y_dot_99        0.188683\n",
       "phi_dot_99      0.024570\n",
       "theta_dot_99    0.022247\n",
       "dtype: float64"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffs = model.predict(xtsm) - ytsm\n",
    "np.max(abs(diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.7913353, 1.6383936, 2.6490834, 1.9456788, 1.945498 , 1.6709379,\n",
       "        1.0960532]], dtype=float32)"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return weights from Keras\n",
    "from keras.models import Model\n",
    "\n",
    "inputData = np.array([[1,2,3,4,5,6,7,8,9,10]])\n",
    "\n",
    "layer_name = 'dense_4'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(inputData)\n",
    "intermediate_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52946097]], dtype=float32)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[4.332323, 5.23232]], dtype = \"float64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.891574, 9.837484]], dtype=float32)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputData = np.array([[4,5]])\n",
    "# merge bias and weights matrices\n",
    "LayerValues = []\n",
    "    \n",
    "# add bias to input data\n",
    "inputData = np.hstack([np.array([1], dtype = \"float32\").reshape(-1,1), inputData] )\n",
    "\n",
    "LayerValues.append(inputData)\n",
    "\n",
    "jj = 0\n",
    "\n",
    "wtsConcatenated = [np.vstack([wts[ii + 1], wts[ii]]) for ii in np.arange(0, len(wts), 2)]\n",
    "nextLayer = np.dot(LayerValues[jj], wtsConcatenated[jj]).astype(\"float32\")\n",
    "nextLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00736949],\n",
       "       [1.3782268 ],\n",
       "       [1.347521  ]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii = 2\n",
    "#wts[0] = np.vstack((np.ones(2, dtype = \"float32\"), wts[0]))\n",
    "\n",
    "np.vstack([wts[ii + 1], wts[ii]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtsConcatenated = [np.vstack([wts[ii + 1], wts[ii]]) for ii in np.arange(0, len(wts), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1, 1, 3]])]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returnLayerValues(wts, inputData= np.array([[1,3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
